{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract generater model\n",
    "\n",
    "Extrat only generater model from GAN model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://chair-generation/models/edges2chair_ikea/checkpoint\r\n",
      "gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565351093.tensorflow-20190806-153451\r\n",
      "gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565698804.tensorflow-20190806-153451\r\n",
      "gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565767058.tensorflow-20190806-153451\r\n",
      "gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1566206506.chair-demo-instance\r\n",
      "gs://chair-generation/models/edges2chair_ikea/graph.pbtxt\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-315065.data-00000-of-00001\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-315065.index\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-315065.meta\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-324165.data-00000-of-00001\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-324165.index\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-324165.meta\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-344565.data-00000-of-00001\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-344565.index\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-344565.meta\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-350165.data-00000-of-00001\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-350165.index\r\n",
      "gs://chair-generation/models/edges2chair_ikea/model-350165.meta\r\n",
      "gs://chair-generation/models/edges2chair_ikea/options.json\r\n"
     ]
    }
   ],
   "source": [
    "# Check target checkpoint\n",
    "!gsutil ls gs://chair-generation/models/edges2chair_ikea/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://chair-generation/models/edges2chair_ikea/checkpoint...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565351093.tensorflow-20190806-153451...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565698804.tensorflow-20190806-153451...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1565767058.tensorflow-20190806-153451...\n",
      "| [4 files][261.4 MiB/261.4 MiB]   26.7 MiB/s                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/events.out.tfevents.1566206506.chair-demo-instance...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/graph.pbtxt...            \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-315065.data-00000-of-00001...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-315065.index...     \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-315065.meta...      \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-324165.data-00000-of-00001...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-324165.index...     \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-324165.meta...      \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-344565.data-00000-of-00001...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-344565.index...     \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-344565.meta...      \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-350165.data-00000-of-00001...\n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-350165.index...     \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/model-350165.meta...      \n",
      "Copying gs://chair-generation/models/edges2chair_ikea/options.json...           \n",
      "\\ [19 files][  2.9 GiB/  2.9 GiB]   20.2 MiB/s                                  \n",
      "Operation completed over 19 objects/2.9 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Copy the model to local\n",
    "!gsutil cp -r gs://chair-generation/models/edges2chair_ikea/ ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Generater Checkpoint and saved model\n",
    "!python ../pix2pix.py \\\n",
    "  --mode export \\\n",
    "  --output_dir ../export/edges2chair_ikea/ \\\n",
    "  --checkpoint ../models/edges2chair_ikea/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to GCS\n",
    "!gsutil cp -r ../export/edges2chair_ikea/ gs://chair-generation/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
      "Created ml engine model [projects/chair-search-demo/models/chair_generation].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create \"chair_generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR=\"gs://chair-generation/export/edges2chair_ikea/export\"\n",
    "VERSION_NAME=\"v1\"\n",
    "MODEL_NAME=\"chair_generation\"\n",
    "FRAMEWORK=\"tensorflow\"\n",
    "\n",
    "!gcloud ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_DIR \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check [Test_saved_model.ipynb](Test_saved_model.ipynb) for JSON file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test model with gcloud command. Output with:\n",
    "    OUTPUT_BYTES\n",
    "    {u'b64': u\"...\"}\n",
    "\"\"\"\n",
    "!gcloud ai-platform predict --model $MODEL_NAME  \\\n",
    "                   --version $VERSION_NAME \\\n",
    "                   --json-instances instance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient \n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_json(project, model, instances, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object.\n",
    "    # To authenticate set the environment variable\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
    "    service = googleapiclient.discovery.build('ml', 'v1',)\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Open and read image as bitstring\n",
    "input_image = open(\"../data/sketch/cpvr2016/train/1.png\", \"rb\").read()\n",
    "print(\"Raw bitstring: \" + str(input_image[:10]) + \" ... \" + str(input_image[-10:]))\n",
    "\n",
    "# Encode image in b64\n",
    "encoded_input_string = base64.b64encode(input_image)\n",
    "input_string = encoded_input_string.decode()\n",
    "request_data = {'image_bytes': {\"b64\": input_string}}\n",
    "\n",
    "output = predict_json(\"chair-search-demo\", \"chair_generation\", request_data, version=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
